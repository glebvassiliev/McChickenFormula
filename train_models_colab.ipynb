{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# F1 Strategy ML Models Training\n",
        "## Train Tire Strategy, Pit Stop, Race Pace, and Position Predictor Models\n",
        "\n",
        "This notebook fetches data from OpenF1 API and trains all 4 ML models for the F1 Strategy Platform.\n",
        "\n",
        "**Instructions:**\n",
        "1. Upload this notebook to Google Colab\n",
        "2. Run all cells sequentially\n",
        "3. Download the generated model files\n",
        "4. Place them in your `backend/models/` directory\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q pandas numpy scikit-learn xgboost lightgbm joblib httpx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import httpx\n",
        "import asyncio\n",
        "import json\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, GradientBoostingRegressor, RandomForestRegressor\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import joblib\n",
        "from zipfile import ZipFile\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"‚úÖ Libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. OpenF1 API Client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "OPENF1_BASE_URL = \"https://api.openf1.org/v1\"\n",
        "\n",
        "async def fetch_openf1(endpoint, params=None):\n",
        "    \"\"\"Fetch data from OpenF1 API\"\"\"\n",
        "    url = f\"{OPENF1_BASE_URL}/{endpoint}\"\n",
        "    async with httpx.AsyncClient(timeout=30.0) as client:\n",
        "        try:\n",
        "            response = await client.get(url, params=params)\n",
        "            response.raise_for_status()\n",
        "            return response.json()\n",
        "        except Exception as e:\n",
        "            print(f\"Error fetching {endpoint}: {e}\")\n",
        "            return []\n",
        "\n",
        "async def get_recent_sessions(year=2024, limit=20):\n",
        "    \"\"\"Get recent F1 sessions\"\"\"\n",
        "    sessions = await fetch_openf1(\"sessions\", {\"year\": year, \"limit\": limit})\n",
        "    return sessions\n",
        "\n",
        "async def get_session_data(session_key):\n",
        "    \"\"\"Get comprehensive data for a session\"\"\"\n",
        "    laps, stints, weather = await asyncio.gather(\n",
        "        fetch_openf1(\"laps\", {\"session_key\": session_key}),\n",
        "        fetch_openf1(\"stints\", {\"session_key\": session_key}),\n",
        "        fetch_openf1(\"weather\", {\"session_key\": session_key}),\n",
        "        return_exceptions=True\n",
        "    )\n",
        "    return {\n",
        "        \"laps\": laps if isinstance(laps, list) else [],\n",
        "        \"stints\": stints if isinstance(stints, list) else [],\n",
        "        \"weather\": weather if isinstance(weather, list) else []\n",
        "    }\n",
        "\n",
        "print(\"‚úÖ OpenF1 client ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Fetch Training Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fetch recent sessions (adjust year if needed)\n",
        "print(\"Fetching recent F1 sessions from OpenF1...\")\n",
        "sessions = await get_recent_sessions(year=2024, limit=30)\n",
        "print(f\"‚úÖ Found {len(sessions)} sessions\\n\")\n",
        "\n",
        "# Display first few sessions\n",
        "for i, session in enumerate(sessions[:5]):\n",
        "    print(f\"{i+1}. {session.get('meeting_name', 'N/A')} - {session.get('session_type', 'N/A')} (Key: {session.get('session_key')})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Collect data from sessions\n",
        "print(\"Collecting session data...\")\n",
        "all_session_data = []\n",
        "\n",
        "for i, session in enumerate(sessions[:10]):  # Use first 10 sessions for training\n",
        "    session_key = session.get('session_key')\n",
        "    if session_key:\n",
        "        print(f\"Processing {i+1}/10: {session.get('meeting_name', 'N/A')}\")\n",
        "        data = await get_session_data(session_key)\n",
        "        data['session_key'] = session_key\n",
        "        all_session_data.append(data)\n",
        "        await asyncio.sleep(0.5)  # Rate limiting\n",
        "\n",
        "print(f\"\\n‚úÖ Collected data from {len(all_session_data)} sessions\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Prepare Training Data\n",
        "\n",
        "Run the data preparation script from the attached file, or use the inline functions below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use the preparation functions (copy from colab_training_script.py or define inline)\n",
        "# For now, we'll use synthetic data generation if OpenF1 data is insufficient\n",
        "\n",
        "# The backend models have built-in synthetic data generation\n",
        "# We'll train using that approach for Colab compatibility\n",
        "\n",
        "print(\"Note: If OpenF1 data is limited, models will use synthetic data for training\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Train All Models\n",
        "\n",
        "We'll use the model classes from the backend, but simplified for Colab. Each model will be trained with either real OpenF1 data (if available) or synthetic data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========== TRAIN TIRE STRATEGY MODEL ==========\n",
        "print(\"Training Tire Strategy Model...\")\n",
        "\n",
        "# Generate or use real data\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingRegressor\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "# Use synthetic data for training (matches backend logic)\n",
        "np.random.seed(42)\n",
        "n_samples = 1000\n",
        "\n",
        "# Create synthetic tire strategy training data\n",
        "tire_data = pd.DataFrame({\n",
        "    \"track_temperature\": np.random.uniform(20, 50, n_samples),\n",
        "    \"air_temperature\": np.random.uniform(15, 40, n_samples),\n",
        "    \"humidity\": np.random.uniform(20, 90, n_samples),\n",
        "    \"track_length\": np.random.uniform(3.0, 7.0, n_samples),\n",
        "    \"number_of_corners\": np.random.randint(10, 25, n_samples),\n",
        "    \"high_speed_corners\": np.random.randint(2, 10, n_samples),\n",
        "    \"low_speed_corners\": np.random.randint(5, 15, n_samples),\n",
        "    \"current_lap\": np.random.randint(1, 50, n_samples),\n",
        "    \"total_laps\": np.random.randint(50, 70, n_samples),\n",
        "    \"remaining_laps\": np.random.randint(1, 50, n_samples),\n",
        "    \"current_position\": np.random.randint(1, 20, n_samples),\n",
        "    \"gap_to_leader\": np.random.uniform(0, 60, n_samples),\n",
        "    \"gap_to_car_ahead\": np.random.uniform(0, 10, n_samples),\n",
        "    \"gap_to_car_behind\": np.random.uniform(0, 10, n_samples),\n",
        "    \"fuel_load\": np.random.uniform(10, 110, n_samples),\n",
        "    \"tire_age\": np.random.randint(0, 30, n_samples),\n",
        "    \"rain_probability\": np.random.uniform(0, 100, n_samples),\n",
        "    \"track_evolution\": np.random.uniform(0, 100, n_samples),\n",
        "    \"safety_car\": np.random.choice([0, 1], n_samples, p=[0.9, 0.1]),\n",
        "    \"vsc\": np.random.choice([0, 1], n_samples, p=[0.95, 0.05]),\n",
        "})\n",
        "\n",
        "# Generate labels\n",
        "def get_compound(row):\n",
        "    if row[\"rain_probability\"] > 70:\n",
        "        return \"WET\" if row[\"rain_probability\"] > 85 else \"INTERMEDIATE\"\n",
        "    if row[\"remaining_laps\"] < 15:\n",
        "        return \"SOFT\"\n",
        "    if row[\"track_temperature\"] > 40:\n",
        "        return \"HARD\"\n",
        "    if row[\"track_temperature\"] < 25:\n",
        "        return \"SOFT\"\n",
        "    return \"MEDIUM\"\n",
        "\n",
        "tire_data[\"optimal_compound\"] = tire_data.apply(get_compound, axis=1)\n",
        "compound_base_stint = {\"SOFT\": 15, \"MEDIUM\": 25, \"HARD\": 35, \"INTERMEDIATE\": 20, \"WET\": 15}\n",
        "tire_data[\"optimal_stint_length\"] = tire_data.apply(\n",
        "    lambda row: compound_base_stint[row[\"optimal_compound\"]] + \n",
        "    np.random.randint(-5, 6) - (row[\"track_temperature\"] - 30) * 0.2, axis=1\n",
        ")\n",
        "tire_data[\"degradation_rate\"] = tire_data.apply(\n",
        "    lambda row: 0.05 + (row[\"track_temperature\"] - 30) * 0.002 +\n",
        "    row[\"high_speed_corners\"] * 0.003 + np.random.uniform(-0.01, 0.01), axis=1\n",
        ")\n",
        "\n",
        "# Prepare features\n",
        "feature_cols = [\n",
        "    \"track_temperature\", \"air_temperature\", \"humidity\", \"track_length\",\n",
        "    \"number_of_corners\", \"high_speed_corners\", \"low_speed_corners\",\n",
        "    \"current_lap\", \"total_laps\", \"remaining_laps\", \"current_position\",\n",
        "    \"gap_to_leader\", \"gap_to_car_ahead\", \"gap_to_car_behind\", \"fuel_load\",\n",
        "    \"tire_age\", \"rain_probability\", \"track_evolution\", \"safety_car\", \"vsc\"\n",
        "]\n",
        "\n",
        "X = tire_data[feature_cols].values\n",
        "scaler_tire = StandardScaler()\n",
        "X_scaled = scaler_tire.fit_transform(X)\n",
        "\n",
        "# Train compound classifier\n",
        "le = LabelEncoder()\n",
        "le.fit(['SOFT', 'MEDIUM', 'HARD', 'INTERMEDIATE', 'WET'])\n",
        "y_compound = le.transform(tire_data[\"optimal_compound\"])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_compound, test_size=0.2, random_state=42)\n",
        "compound_classifier = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1)\n",
        "compound_classifier.fit(X_train, y_train)\n",
        "compound_accuracy = compound_classifier.score(X_test, y_test)\n",
        "print(f\"  Compound Accuracy: {compound_accuracy:.4f}\")\n",
        "\n",
        "# Train stint regressor\n",
        "y_stint = tire_data[\"optimal_stint_length\"].values\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_stint, test_size=0.2, random_state=42)\n",
        "stint_regressor = GradientBoostingRegressor(n_estimators=100, max_depth=6, random_state=42)\n",
        "stint_regressor.fit(X_train, y_train)\n",
        "stint_r2 = stint_regressor.score(X_test, y_test)\n",
        "print(f\"  Stint R¬≤: {stint_r2:.4f}\")\n",
        "\n",
        "# Train degradation regressor\n",
        "y_degradation = tire_data[\"degradation_rate\"].values\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_degradation, test_size=0.2, random_state=42)\n",
        "degradation_regressor = GradientBoostingRegressor(n_estimators=100, max_depth=6, random_state=42)\n",
        "degradation_regressor.fit(X_train, y_train)\n",
        "degradation_r2 = degradation_regressor.score(X_test, y_test)\n",
        "print(f\"  Degradation R¬≤: {degradation_r2:.4f}\")\n",
        "\n",
        "# Save model\n",
        "tire_model = {\n",
        "    'compound_classifier': compound_classifier,\n",
        "    'stint_regressor': stint_regressor,\n",
        "    'degradation_regressor': degradation_regressor,\n",
        "    'scaler': scaler_tire,\n",
        "    'label_encoder': le,\n",
        "    'is_trained': True\n",
        "}\n",
        "\n",
        "joblib.dump(tire_model, 'tire_strategy_model.joblib')\n",
        "print(\"‚úÖ Tire Strategy Model saved!\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========== TRAIN PIT STOP PREDICTOR ==========\n",
        "print(\"Training Pit Stop Predictor...\")\n",
        "\n",
        "# Generate synthetic pit stop data (matches backend)\n",
        "np.random.seed(42)\n",
        "n_samples = 800\n",
        "\n",
        "pit_data = pd.DataFrame({\n",
        "    \"current_lap\": np.random.randint(1, 55, n_samples),\n",
        "    \"total_laps\": np.random.randint(50, 70, n_samples),\n",
        "    \"remaining_laps\": np.random.randint(1, 55, n_samples),\n",
        "    \"tire_age\": np.random.randint(0, 35, n_samples),\n",
        "    \"tire_compound_idx\": np.random.randint(0, 3, n_samples),\n",
        "    \"current_position\": np.random.randint(1, 20, n_samples),\n",
        "    \"gap_to_car_ahead\": np.random.exponential(3, n_samples),\n",
        "    \"gap_to_car_behind\": np.random.exponential(3, n_samples),\n",
        "    \"pit_delta\": np.random.uniform(18, 26, n_samples),\n",
        "    \"track_position_value\": np.random.uniform(30, 80, n_samples),\n",
        "    \"tire_degradation_rate\": np.random.uniform(0.02, 0.12, n_samples),\n",
        "    \"current_pace_delta\": np.random.normal(0, 0.5, n_samples),\n",
        "    \"competitor_tire_age\": np.random.randint(0, 35, n_samples),\n",
        "    \"competitor_compound_idx\": np.random.randint(0, 3, n_samples),\n",
        "    \"fuel_adjusted_pace\": np.random.normal(0, 0.3, n_samples),\n",
        "    \"traffic_density\": np.random.randint(0, 15, n_samples),\n",
        "    \"safety_car_probability\": np.random.uniform(0, 30, n_samples),\n",
        "    \"drs_available\": np.random.choice([0, 1], n_samples, p=[0.3, 0.7]),\n",
        "    \"track_temperature\": np.random.uniform(20, 50, n_samples),\n",
        "    \"rain_probability\": np.random.uniform(0, 100, n_samples),\n",
        "})\n",
        "\n",
        "pit_data[\"in_pit_window\"] = ((pit_data[\"tire_age\"] > 12) & (pit_data[\"tire_age\"] < 35) & (pit_data[\"remaining_laps\"] > 10)).astype(int)\n",
        "pit_data[\"undercut_opportunity\"] = ((pit_data[\"gap_to_car_ahead\"] < pit_data[\"pit_delta\"] * 0.15) & (pit_data[\"tire_age\"] > pit_data[\"competitor_tire_age\"]) & (pit_data[\"in_pit_window\"] == 1)).astype(int)\n",
        "compound_stint = {0: 15, 1: 25, 2: 35}\n",
        "pit_data[\"optimal_pit_lap\"] = pit_data.apply(lambda row: row[\"current_lap\"] + compound_stint[row[\"tire_compound_idx\"]] - row[\"tire_age\"] + np.random.randint(-3, 4), axis=1)\n",
        "\n",
        "# Train models\n",
        "feature_cols = [\"current_lap\", \"total_laps\", \"remaining_laps\", \"tire_age\", \"tire_compound_idx\", \"current_position\", \n",
        "                \"gap_to_car_ahead\", \"gap_to_car_behind\", \"pit_delta\", \"track_position_value\", \"tire_degradation_rate\",\n",
        "                \"current_pace_delta\", \"competitor_tire_age\", \"competitor_compound_idx\", \"fuel_adjusted_pace\",\n",
        "                \"traffic_density\", \"safety_car_probability\", \"drs_available\", \"track_temperature\", \"rain_probability\"]\n",
        "\n",
        "X = pit_data[feature_cols].values\n",
        "scaler_pit = StandardScaler()\n",
        "X_scaled = scaler_pit.fit_transform(X)\n",
        "\n",
        "# Pit window classifier\n",
        "y_window = pit_data[\"in_pit_window\"].values\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_window, test_size=0.2, random_state=42)\n",
        "pit_window_classifier = GradientBoostingClassifier(n_estimators=100, max_depth=6, random_state=42)\n",
        "pit_window_classifier.fit(X_train, y_train)\n",
        "print(f\"  Pit Window Accuracy: {pit_window_classifier.score(X_test, y_test):.4f}\")\n",
        "\n",
        "# Undercut classifier\n",
        "y_undercut = pit_data[\"undercut_opportunity\"].values\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_undercut, test_size=0.2, random_state=42)\n",
        "undercut_classifier = GradientBoostingClassifier(n_estimators=100, max_depth=6, random_state=42)\n",
        "undercut_classifier.fit(X_train, y_train)\n",
        "print(f\"  Undercut Accuracy: {undercut_classifier.score(X_test, y_test):.4f}\")\n",
        "\n",
        "# Optimal lap regressor\n",
        "y_optimal = pit_data[\"optimal_pit_lap\"].values\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_optimal, test_size=0.2, random_state=42)\n",
        "optimal_lap_regressor = GradientBoostingRegressor(n_estimators=100, max_depth=6, random_state=42)\n",
        "optimal_lap_regressor.fit(X_train, y_train)\n",
        "print(f\"  Optimal Lap R¬≤: {optimal_lap_regressor.score(X_test, y_test):.4f}\")\n",
        "\n",
        "# Save\n",
        "pit_model = {\n",
        "    'pit_window_classifier': pit_window_classifier,\n",
        "    'undercut_classifier': undercut_classifier,\n",
        "    'optimal_lap_regressor': optimal_lap_regressor,\n",
        "    'scaler': scaler_pit,\n",
        "    'is_trained': True\n",
        "}\n",
        "joblib.dump(pit_model, 'pit_stop_model.joblib')\n",
        "print(\"‚úÖ Pit Stop Predictor saved!\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========== TRAIN RACE PACE ANALYZER ==========\n",
        "print(\"Training Race Pace Analyzer...\")\n",
        "\n",
        "# Generate synthetic pace data\n",
        "np.random.seed(42)\n",
        "n_samples = 1200\n",
        "\n",
        "base_time = 88.0\n",
        "compound_effect = {0: -0.3, 1: 0, 2: 0.4}\n",
        "\n",
        "pace_data = pd.DataFrame({\n",
        "    \"lap_number\": np.random.randint(1, 60, n_samples),\n",
        "    \"fuel_load\": np.random.uniform(5, 110, n_samples),\n",
        "    \"tire_age\": np.random.randint(0, 35, n_samples),\n",
        "    \"tire_compound_idx\": np.random.randint(0, 3, n_samples),\n",
        "    \"track_temperature\": np.random.uniform(20, 50, n_samples),\n",
        "    \"air_temperature\": np.random.uniform(15, 40, n_samples),\n",
        "    \"track_evolution\": np.random.uniform(0, 100, n_samples),\n",
        "    \"traffic\": np.random.randint(0, 5, n_samples),\n",
        "    \"drs_enabled\": np.random.choice([0, 1], n_samples, p=[0.3, 0.7]),\n",
        "    \"sector1_time\": np.random.uniform(25, 35, n_samples),\n",
        "    \"sector2_time\": np.random.uniform(30, 40, n_samples),\n",
        "    \"previous_lap_time\": np.random.uniform(85, 95, n_samples),\n",
        "    \"best_lap_time\": np.random.uniform(84, 88, n_samples),\n",
        "    \"avg_lap_time\": np.random.uniform(86, 92, n_samples),\n",
        "    \"position\": np.random.randint(1, 20, n_samples),\n",
        "    \"wind_speed\": np.random.uniform(0, 30, n_samples),\n",
        "    \"humidity\": np.random.uniform(20, 90, n_samples),\n",
        "    \"safety_car_laps\": np.random.randint(0, 10, n_samples),\n",
        "    \"push_level\": np.random.uniform(50, 100, n_samples),\n",
        "    \"battery_deployment\": np.random.uniform(30, 100, n_samples),\n",
        "})\n",
        "\n",
        "pace_data[\"lap_time\"] = pace_data.apply(\n",
        "    lambda row: base_time + compound_effect[row[\"tire_compound_idx\"]] +\n",
        "    row[\"fuel_load\"] * 0.03 + row[\"tire_age\"] * 0.04 + row[\"traffic\"] * 0.3 +\n",
        "    (row[\"track_temperature\"] - 30) * 0.02 + np.random.normal(0, 0.3), axis=1\n",
        ")\n",
        "pace_data[\"fuel_effect\"] = 0.03 + np.random.normal(0, 0.002, n_samples)\n",
        "pace_data[\"pace_trend\"] = pace_data.apply(lambda row: row[\"tire_age\"] * 0.03 + np.random.normal(0, 0.05), axis=1)\n",
        "\n",
        "# Train models\n",
        "feature_cols = [\"lap_number\", \"fuel_load\", \"tire_age\", \"tire_compound_idx\", \"track_temperature\", \"air_temperature\",\n",
        "                \"track_evolution\", \"traffic\", \"drs_enabled\", \"sector1_time\", \"sector2_time\", \"previous_lap_time\",\n",
        "                \"best_lap_time\", \"avg_lap_time\", \"position\", \"wind_speed\", \"humidity\", \"safety_car_laps\",\n",
        "                \"push_level\", \"battery_deployment\"]\n",
        "\n",
        "X = pace_data[feature_cols].values\n",
        "scaler_pace = StandardScaler()\n",
        "X_scaled = scaler_pace.fit_transform(X)\n",
        "\n",
        "# Lap time regressor\n",
        "y_lap_time = pace_data[\"lap_time\"].values\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_lap_time, test_size=0.2, random_state=42)\n",
        "lap_time_regressor = GradientBoostingRegressor(n_estimators=150, max_depth=8, learning_rate=0.1, random_state=42)\n",
        "lap_time_regressor.fit(X_train, y_train)\n",
        "print(f\"  Lap Time R¬≤: {lap_time_regressor.score(X_test, y_test):.4f}\")\n",
        "\n",
        "# Fuel effect regressor\n",
        "y_fuel_effect = pace_data[\"fuel_effect\"].values\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_fuel_effect, test_size=0.2, random_state=42)\n",
        "fuel_effect_regressor = RandomForestRegressor(n_estimators=100, max_depth=6, random_state=42, n_jobs=-1)\n",
        "fuel_effect_regressor.fit(X_train, y_train)\n",
        "print(f\"  Fuel Effect R¬≤: {fuel_effect_regressor.score(X_test, y_test):.4f}\")\n",
        "\n",
        "# Trend regressor\n",
        "y_trend = pace_data[\"pace_trend\"].values\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_trend, test_size=0.2, random_state=42)\n",
        "trend_regressor = GradientBoostingRegressor(n_estimators=100, max_depth=6, random_state=42)\n",
        "trend_regressor.fit(X_train, y_train)\n",
        "print(f\"  Trend R¬≤: {trend_regressor.score(X_test, y_test):.4f}\")\n",
        "\n",
        "# Save\n",
        "pace_model = {\n",
        "    'lap_time_regressor': lap_time_regressor,\n",
        "    'fuel_effect_regressor': fuel_effect_regressor,\n",
        "    'trend_regressor': trend_regressor,\n",
        "    'scaler': scaler_pace,\n",
        "    'is_trained': True\n",
        "}\n",
        "joblib.dump(pace_model, 'race_pace_model.joblib')\n",
        "print(\"‚úÖ Race Pace Analyzer saved!\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========== TRAIN POSITION PREDICTOR ==========\n",
        "print(\"Training Position Predictor...\")\n",
        "\n",
        "# Generate synthetic position data\n",
        "np.random.seed(42)\n",
        "n_samples = 1000\n",
        "\n",
        "position_data = pd.DataFrame({\n",
        "    \"current_position\": np.random.randint(1, 20, n_samples),\n",
        "    \"lap_number\": np.random.randint(1, 60, n_samples),\n",
        "    \"remaining_laps\": np.random.randint(1, 55, n_samples),\n",
        "    \"gap_to_car_ahead\": np.random.exponential(2, n_samples),\n",
        "    \"gap_to_car_behind\": np.random.exponential(2, n_samples),\n",
        "    \"relative_pace\": np.random.normal(0, 0.5, n_samples),\n",
        "    \"tire_advantage\": np.random.randint(-15, 16, n_samples),\n",
        "    \"compound_advantage\": np.random.choice([-1, 0, 1], n_samples),\n",
        "    \"drs_available\": np.random.choice([0, 1], n_samples, p=[0.3, 0.7]),\n",
        "    \"battery_level\": np.random.uniform(30, 100, n_samples),\n",
        "    \"straight_length\": np.random.uniform(500, 1500, n_samples),\n",
        "    \"overtaking_difficulty\": np.random.uniform(20, 90, n_samples),\n",
        "    \"track_position_value\": np.random.uniform(30, 80, n_samples),\n",
        "    \"driver_aggression\": np.random.uniform(30, 90, n_samples),\n",
        "    \"car_performance_delta\": np.random.normal(0, 0.3, n_samples),\n",
        "    \"weather_stability\": np.random.uniform(50, 100, n_samples),\n",
        "    \"safety_car_probability\": np.random.uniform(0, 30, n_samples),\n",
        "    \"laps_since_pit\": np.random.randint(0, 30, n_samples),\n",
        "    \"competitor_laps_since_pit\": np.random.randint(0, 30, n_samples),\n",
        "    \"points_position\": np.random.randint(1, 20, n_samples),\n",
        "})\n",
        "\n",
        "position_data[\"overtake_success\"] = ((position_data[\"gap_to_car_ahead\"] < 1.0) & \n",
        "                                       (position_data[\"relative_pace\"] < -0.2) & \n",
        "                                       (position_data[\"drs_available\"] == 1) & \n",
        "                                       (position_data[\"overtaking_difficulty\"] < 70)).astype(int)\n",
        "position_data[\"position_change\"] = position_data.apply(\n",
        "    lambda row: 1 if row[\"overtake_success\"] else (0 if row[\"gap_to_car_behind\"] < 0.5 and row[\"relative_pace\"] > 0.3 else 0) + 1, axis=1\n",
        ")\n",
        "\n",
        "# Train models\n",
        "feature_cols = [\"current_position\", \"lap_number\", \"remaining_laps\", \"gap_to_car_ahead\", \"gap_to_car_behind\",\n",
        "                \"relative_pace\", \"tire_advantage\", \"compound_advantage\", \"drs_available\", \"battery_level\",\n",
        "                \"straight_length\", \"overtaking_difficulty\", \"track_position_value\", \"driver_aggression\",\n",
        "                \"car_performance_delta\", \"weather_stability\", \"safety_car_probability\", \"laps_since_pit\",\n",
        "                \"competitor_laps_since_pit\", \"points_position\"]\n",
        "\n",
        "X = position_data[feature_cols].values\n",
        "scaler_position = StandardScaler()\n",
        "X_scaled = scaler_position.fit_transform(X)\n",
        "\n",
        "# Overtake classifier\n",
        "y_overtake = position_data[\"overtake_success\"].values\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_overtake, test_size=0.2, random_state=42)\n",
        "overtake_classifier = GradientBoostingClassifier(n_estimators=100, max_depth=6, random_state=42)\n",
        "overtake_classifier.fit(X_train, y_train)\n",
        "print(f\"  Overtake Accuracy: {overtake_classifier.score(X_test, y_test):.4f}\")\n",
        "\n",
        "# Position change classifier\n",
        "y_change = position_data[\"position_change\"].values\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_change, test_size=0.2, random_state=42)\n",
        "position_change_classifier = RandomForestClassifier(n_estimators=100, max_depth=8, random_state=42, n_jobs=-1)\n",
        "position_change_classifier.fit(X_train, y_train)\n",
        "print(f\"  Position Change Accuracy: {position_change_classifier.score(X_test, y_test):.4f}\")\n",
        "\n",
        "# Save\n",
        "position_model = {\n",
        "    'overtake_classifier': overtake_classifier,\n",
        "    'position_change_classifier': position_change_classifier,\n",
        "    'scaler': scaler_position,\n",
        "    'is_trained': True\n",
        "}\n",
        "joblib.dump(position_model, 'position_model.joblib')\n",
        "print(\"‚úÖ Position Predictor saved!\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Download Models\n",
        "\n",
        "Download all trained model files and place them in your `backend/models/` directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List all generated model files\n",
        "from pathlib import Path\n",
        "from zipfile import ZipFile\n",
        "from datetime import datetime\n",
        "\n",
        "print(\"Generated model files:\")\n",
        "model_files = []\n",
        "for file in Path('.').glob('*_model.joblib'):\n",
        "    size_mb = file.stat().st_size / (1024 * 1024)\n",
        "    print(f\"  ‚úÖ {file.name} ({size_mb:.2f} MB)\")\n",
        "    model_files.append(file.name)\n",
        "\n",
        "# Create zip file for easy download\n",
        "if model_files:\n",
        "    zip_filename = f'f1_models_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.zip'\n",
        "    with ZipFile(zip_filename, 'w') as zipf:\n",
        "        for model_file in model_files:\n",
        "            zipf.write(model_file)\n",
        "    \n",
        "    print(f\"\\nüì¶ Created zip file: {zip_filename}\")\n",
        "    print(f\"\\nüì• Download the models:\")\n",
        "    print(f\"   1. Download the zip file or individual .joblib files\")\n",
        "    print(f\"   2. Extract to: backend/models/\")\n",
        "    print(f\"   3. Restart your backend server\")\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è No model files found!\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
